
data:
  dataset_name: 'CT2PET_translation' 
  dataset_type: 'custom_aligned'
  dataset_config:
    max_pixel_ori: 32767 # Pet 
    max_pixel_cond: 2047  # CT
    dataset_path: 'path/to/dataset'
    image_size: 256
    channels: 1
    to_normal: True 
    flip: False
  train:
    batch_size: 16
    shuffle: True
  val:
    batch_size: 16
    shuffle: True
  test:
    batch_size: 10
    shuffle: False
model: 
  BB: 
    CT_condition: True # True if using CT latent as condition, False if not
    lr_scheduler:
      cooldown: 3000
      factor: 0.5
      min_lr: 5.0e-07
      patience: 3000
      threshold: 0.0001
    optimizer: 
      beta1: 0.9
      lr: 0.0001
      optimizer: Adam
      weight_decay: 0.0
    params: 
      UNetParams:
        attention_resolutions: !!python/tuple
        - 32
        - 16
        - 8
        channel_mult: !!python/tuple
        - 1
        - 2
        - 3
        - 4
        condition_key: SpatialRescaler
        context_dim:
        conv_resample: True
        dims: 2
        image_size: 64
        in_channels: 12
        model_channels: 128
        num_head_channels: 64
        num_heads: 8
        num_res_blocks: 2
        out_channels: 3
        resblock_updown: True
        use_scale_shift_norm: True
        use_spatial_transformer: False
      eta: 1.0
      loss_type: l1
      max_var: 1.0
      mt_type: linear
      num_timesteps: 1000
      objective: x0
      sample_step: 200
      sample_type: linear
      skip_sample: True
  CondStageParams: 
    in_channels: 1
    n_stages: 2
    out_channels: 3
  EMA: 
    ema_decay: 0.995
    start_ema_step: 30000
    update_ema_interval: 8
    use_ema: True
  VQGAN: 
    params:
      ckpt_path: 'ckpt_path' # path to the pretrained VQGAN checkpoint
      ddconfig: 
        attn_resolutions: []
        ch: 128
        ch_mult: !!python/tuple
        - 1
        - 2
        - 4
        double_z: False
        dropout: 0.0
        in_channels: 1
        out_ch: 1
        num_res_blocks: 1
        
        resolution: 256
        z_channels: 3
      embed_dim: 3
      lossconfig: 
        target: torch.nn.Identity
      n_embed: 8192
  latent_before_quant_conv: False
  attention_map_train_path: 'path/to/training/samples/of/segmentor'
  attention_map_val_path: 'path/to/validation-or-testing/samples/of/segmentor' 
  model_name: RegCPDM
  model_type: CPDM
  normalize_latent: False
  only_load_latent_mean_std: False
  # model_load_path: 'model_load_path'
  # optim_sche_load_path: 'optim_sche_load_path'
reg:  # Registration Regularization parameters, if not using registration, set to None or remove
  lambda1: 0.7 
  lambda2: 0.35
runner: CPDMRunner
testing: 
  clip_denoised: False 
  sample_num: 1
training: 
  accumulate_grad_batches: 4
  n_epochs: 210
  n_steps: 200000
  sample_interval: 1
  save_interval: 1
  validation_interval: 1